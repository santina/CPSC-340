{
    "contents" : "#install.packages('lm')\n#library(lm)\n\n#this file is heavily commented and modified with added new lines of code \n#after being downloaded from the course website \n\n#'build a  model for something (house price) as a function of the factors \"area\n#'and number of bedroom\n#'differnce is that we're not catagorizigng prices \n#'we're building a numerical model = regression\n#'then we can use logistic regression to classiy catagorial data, like last week \n\n#=============Part 1: age and heigth=============================\n\ntrain<- read.table(\"age-height-train.csv\", sep = \",\", header = TRUE)\ntest <- read.table(\"age-height-test.csv\", sep = \",\", header = TRUE)\n#train\nplot(train$x, train$y,ylab='Height in meters',xlab='Age in years')\n\nlr_model  <- lm(y ~x, data = train) #0.73 0.0663 \n# H = 0.0663A + 0.73 \n\nlr_model = lm(y~x,data=train) # equal sign? \nlr_model\nsummary(lr_model)\nabline(lr_model,col=\"green\") #draw a green line for linear regression \n\n#interval = \"prediction\" has to do with confidence intervals (lower and upper)\n  #can go look up ?predict for more details \nprediction <- predict(lr_model,interval=\"prediction\",newdata=test)\nprediction  #what's lower and upper? \nprediction <- as.data.frame(prediction)\n\n#plot test data points \npoints(test$x,test$y,col=\"red\")\n\n#what does this line mean? : \npoints(test$x,prediction$fit,col=\"blue\",pch=17)\n\n#bind the y of testing data with the \"fit\" from prediction\n#if prediction is good, they shouldn't differ much \ncbind(test$y , prediction$fit)\n\n\n\n########### PART 2 ##############\n#look at residuals to compare unscale and scaled \n#which one is better, why? \n\ntrain <- read.table(\"housing-train.csv\",sep = \",\",header=TRUE)\ntest <- read.table(\"housing-test.csv\",sep = \",\",header=TRUE)\n\n#optional plots \nplot(train$price, train$area,xlab='Price',ylab='Area')\nplot(train$price, train$bedrooms,xlab='Price',ylab='Number of bedrooms')\n#another nice optional plot \npairs(~price +area+bedrooms, data=train)\n\nmodel <- lm(price ~ area + bedrooms, data=train)\nmodel  #P = 136.9A - 14085B + 108413 \nsummary(model)\nplot(model) #don't need to undestand all the plots \n\n#The first plot gives an idea of whether there is any curvature in the data. \n# If the red line is strongly curved, a quadratic or other model may be better. \n# |Yp- Ye| second plot \n# Third: \n# Fourth: if you move one point would fit change drasticaly \n#  (less important at this stage) The second plot is to check whether the residuals (y-y^) are normally distributed. \n# The third plot is used to check if the variance is contant \n# (ie, if the standard deviation among the residuals appears to be about constant). \n# If the red line is strongly tilted up/down, that is a red flag.\n# (less important at this stage) The last plot is used to check to see if there were any \n# overly influential points \n\n\nhist(resid(model)) #residue on training data \n\nprediction2 <- predict(model,interval=\"prediction\",newdata=test)\nprediction2 <- as.data.frame(prediction2)\n# view the real and predicted prices\ncbind(test$price , prediction2$fit)\ncbind(test$price , prediction2$fit, abs(test$price - prediction2$fit))\n\n#calculate residual sum \nsum(abs(test$price-prediction2$fit))/length(test$price)\n\n#===============PART 2.2======================\n# optional: use scale() function\nfeature.scale = function (dataset, columns) {\n  for (column in columns) {\n    sigma = sd(dataset[,column])\n    mu = mean(dataset[,column])\n    dataset[paste(names(dataset[column]), \".scale\", sep = \"\")] = (dataset[,column] - mu)/sigma\n  }\n  return(dataset)\n}\n\ntrain.scaled <- feature.scale(train, c(\"area\", \"bedrooms\"))\ntest.scaled <- feature.scale(test, c(\"area\", \"bedrooms\"))\n#model.scale <- lm(price ~ scale(area) + scale(bedrooms), data=train)\nmodel.scale <- lm(price ~ area.scale + bedrooms.scale, data=train.scaled)\nmodel.scale  # P = 114289A - 11079B + 342997 \nplot(model.scale)\nhist(resid(model.scale))\nprediction.scale <- predict(model.scale,interval=\"prediction\",newdata=test.scaled)\nprediction.scale <- as.data.frame(prediction.scale)\n# view the real and predicted prices\ncbind(test$price , prediction.scale$fit)\n\n# for scaled data: The residuals average:\nsum(abs(test$price-prediction.scale$fit))/length(test$price)\n# error = 1/n * summation(i=1, n){y_p - y_e}   y_p: prediction price, y_e acutal price for test\n\n#or this is the right way to do it? specify \"scaled\" data \nsum(abs(test.scaled$price-prediction.scale$fit))/length(test.scaled$price)\n#acutally both gives the same sum of residuals 39722.82 \n\ncbind(test$price , prediction.scale$fit)\n\n# try find residues in test (train is already looked at )",
    "created" : 1425522367161.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3254118018",
    "id" : "722398F6",
    "lastKnownWriteTime" : 1412665194,
    "path" : "C:/Users/Santina Lin/SkyDrive/CPSC340/Tutorials/Tutorial3/Tutorial-3-scripts.R",
    "project_path" : "Tutorials/Tutorial3/Tutorial-3-scripts.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}