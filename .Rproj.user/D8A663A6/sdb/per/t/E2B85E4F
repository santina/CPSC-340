{
    "contents" : "# Assignment 4 : SVM and cross-validation on text data \n# Santina Lin (87325149)\n\n# important libraries: \nlibrary(tm)         # for text mining \nlibrary(SnowballC)  # for using stemmming, finding common roots of words \nlibrary(plyr)       # for easy computation with data frames\nlibrary(dplyr)      # do this after loading plyr\nlibrary(e1071)      # for SVM\n\n# this contains Corpus processing, get vector of classes, and confusion matrix\nsource('./helperFunctions.R')\n\n# ====================== Part 1: create a SVM classifier ====================== \n\n#' LOAD THE DATASET \n#'loop through each folder in training, create vector for classes depending on file name, \n#'also Corpus for each foldrer, process each, \n\n# get the list of file names \ntraining_files <- list.files(\"20news-bydate-train\", full.name = TRUE)\ntesting_files  <- list.files(\"20news-bydate-test\", full.name = TRUE)\n\n# get their classes\ntrainClass  <- getClasses(training_files) #11314 files in total \ntestClass  <- getClasses(testing_files)   #7532 files in total\n# you must absolutely do this otherwise SVM won't work. 0 and 1 must be read as factors\ntrain_classes <- as.factor(trainClass)\ntest_classes <- as.factor(testClass)\n\n# loop through each, store corpus in list for training data\ntrainCorpusList <- alply(training_files, .margin = 1, function(f){\n  singleCorpus <- Corpus(DirSource(f,  encoding=\"UTF-8\"))\n})\n# same thing, for testing data \ntestCorpusList <- alply(testing_files, .margin = 1, function(f){\n\tsingleCorpus <- Corpus(DirSource(f,  encoding=\"UTF-8\"))\n})\n#' reason I did this instead of loading it like DirSource(testing_files)\n#' I want to make sure the order remain the same so I can use the classes vector \n#' correctly. Loading it like that might mess up the order \n\n# 20 elements, 91Mb wow. Now give name to each element in the list \nnames(trainCorpusList) <- list.files(\"20news-bydate-train\", full.name = FALSE)\nnames(testCorpusList) <- list.files(\"20news-bydate-test\", full.name = FALSE)\n\ntrainCorpusList <- processCorpusList(trainCorpusList) # 20\ntestCorpusList <- processCorpusList(testCorpusList)   # 20\ntogetherCorpus  <- c(trainCorpusList, testCorpusList)\n\n\n# check if it works, to extract out the element, use double bracket [[]]\n# inspect(trainCorpusList[[\"talk.religion.misc\"]]) \n\n# combine all corpuses togeter into one big one\nallCorpus_train <- do.call(function(...) c(..., recursive = TRUE), trainCorpusList)\nallCorpus_test <- do.call(function(...) c(..., recursive = TRUE), testCorpusList)\nallCorpus  <- do.call(function(...) c(..., recursive = TRUE), togetherCorpus)\n\n\n# then do document term freq and remove sparse term on them \n# (discussion board) I should prob combine the train and test together and then make DTM \n# and remove sparse term and separate them into their own dat frames so \n# that there won't be diferet numbers of terms \n\n# DTM_train <- DocumentTermMatrix(allCorpus_train,control=list(stemming = TRUE,weighting = weightTfIdf))\n# DTM_test <- DocumentTermMatrix(allCorpus_test,control=list(stemming = TRUE,weighting = weightTfIdf))\n\nDTM_all <- DocumentTermMatrix(allCorpus,control=list(stemming = TRUE,weighting = weightTfIdf))\n# row: 18846 (number of documents) col = 104532 number of terms, sparsity 100%\n\nDTM_all2 <- removeSparseTerms(DTM_all, sparse=0.91) \n# col = 120\n\nDTM_all2 <- as.data.frame(inspect(DTM_all2))\nDTM_all2_train <- DTM_all2[1:11314, ] \nDTM_all2_test  <- tail(DTM_all2, 7532)\n# 11314: number of files in training set\n\n\n# SVM classifications, train on the training set and its classes\nSVM <- svm(DTM_all2_train,train_classes,kernel=\"linear\") \n\nPredictionSVM <- predict(SVM,DTM_all2_test)\npredictionSummary <- table(PredictionSVM,test_classes)\n#             test_classes\n#PredictionSVM    0    1\n#             0 5268 1299\n#             1  309  656\n\nprop.table(table(test_classes==PredictionSVM))  # 83% accuracy\n\nTN <- predictionSummary[1,1]\nFN <- predictionSummary[1,2]\nFP <- predictionSummary[2,1]\nTP <- predictionSummary[2,2]\n\n\n#I'll treat 1 (comp) as positive \nspecificity <- TN/(TN+FP)  #0.9315044\nsensitivity <- TP/(TP+FN)  #0.4736573\n\n# ================= PART 2: 5-Fold Cross Validation ====================\n\n# random seed for this class\nset.seed(340)\n\n# DTM_all2 is the DTM (with sparse term removed) that has all the data (train + test )\n# train_classes and test_classes correspond to the first 11314 and the remining\n# (in order ) of the data\n\n# bind the data frame with all data and their classes (0 or 1) together \n\nDTM_all2$class <- factor(c(trainClass, testClass))\n\n# shuffle the rows \nDTM_all2_shuffled <- DTM_all2[sample(nrow(DTM_all2)), ]\n\n# split into 5 parts \nsize  <- nrow(DTM_all2_shuffled)/5 \n# 3769.2, doesn't divide evenly, make last set with 3770 \nsize <- round(nrow(DTM_all2_shuffled)/5)\n\nset1 <- head(DTM_all2_shuffled, size)\nset2 <- DTM_all2_shuffled[(size+1):(size*2), ]\nset3 <- DTM_all2_shuffled[(size*2+1):(size*3), ]\nset4 <- DTM_all2_shuffled[(size*3+1):(size*4), ]\nset5 <- tail(DTM_all2_shuffled, 3770)\n\n# the next 5 lines take forever. \ntable1 <- getConfusionMatrix_SVM(set1, set2, set3, set4, set5)\ntable2 <- getConfusionMatrix_SVM(set2, set1, set3, set4, set5)\ntable3 <- getConfusionMatrix_SVM(set3, set2, set1, set4, set5)\ntable4 <- getConfusionMatrix_SVM(set4, set2, set3, set1, set5)\ntable5 <- getConfusionMatrix_SVM(set5, set2, set3, set4, set1)\n\n# sum up the tables \nsummary <- data.frame()\nsummary[1,1] <- table1[1,1] + table2[1,1] + table3[1,1] + table4[1,1] + table5[1,1]\nsummary[1,2] <- table1[1,2] + table2[1,2] + table3[1,2] + table4[1,2] + table5[1,2]\nsummary[2,1] <- table1[2,1] + table2[2,1] + table3[2,1] + table4[2,1] + table5[2,1]\nsummary[2,2] <- table1[2,2] + table2[2,2] + table3[2,2] + table4[2,2] + table5[2,2]\ncolnames(summary) <- c(0,1) \nrownames(summary) <- c(0,1)\n\nTN_CV <- summary[1,1]\nFN_CV <- summary[1,2]\nFP_CV <- summary[2,1]\nTP_CV <- summary[2,2]\n\n\n#I'll treat 1 (comp) as positive \nspecificity_CV <- TN_CV/(TN_CV+FP_CV)  # 0.9330706\nsensitivity_CV <- TP_CV/(TP_CV+FN_CV)  # 0.4745451\n",
    "created" : 1416439022665.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2745803032",
    "id" : "E2B85E4F",
    "lastKnownWriteTime" : 1416495857,
    "path" : "C:/Users/Santina Lin/SkyDrive/CPSC340/Assignments_cs340/Assignment4/Assign4_SantinaLin.R",
    "project_path" : "Assignments_cs340/Assignment4/Assign4_SantinaLin.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}