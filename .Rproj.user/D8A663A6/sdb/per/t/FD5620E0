{
    "contents" : "\n# Tutorial 5c, Oct 27 Monday. Santina Lin \n# below codes are from the connect website. I have added a lot of comments as notes \n\nset.seed(1) # though people seem to get different results \n\n# require to load those two first \nlibrary(\"grid\")\nlibrary(\"MASS\")\n\n# download if you don't have it \nlibrary(\"neuralnet\")\n\nwine <- read.table(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",sep=\",\")\n#wine <- read.table(\"wine.data\",head=TRUE,sep=\",\")\nhead(wine) # there are 14 variables \n\n# gonna try to predict what kind fo wines we have. V1 is type of wine\n\n#randomize order of rows\nwine = wine[sample(nrow(wine)),]  # now the order of the rows are randomized \nwine_train = wine[1:100,]\nwine_test = wine[101:178,]\n\n# train a neuralnet model based on all features, calculate time in the meantime \n# system.time command time how long this will take\n# can try changing hidden node number to see performance : \n# perhaps roughly similar to number of variables. TA isn't sure, put on discussion board \nsystem.time(modelnn <- neuralnet(\n  V1 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 +\n    V11 + V12 + V13 + V14, wine_train, hidden = 10, algorithm='rprop+',learningrate=0.01,rep=1))\n\n# get the test set in the format that neuralnet compute accepts\n# why only from V2 to V13? what happened to V14? error, fixed \ntemp_test <- subset(wine_test,select = \n                      c(\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\", \"V14\"))\n\n# calculate accuracy (true) --> compute is a fucntion that predict in neuralnet library\n# compute : false : 0.65, TRUE: 0.346.... which is different from the TA's result \nprop.table(table(wine_test$V1 == round((compute(modelnn, temp_test))$net.result)))\n\n# ============part 2 : PCA ================================ \n# PCA: way to understand data better \" \n\nlibrary(\"prcomp\")\n\n# first scale the data \nwine_train_scaled <- as.data.frame(scale(wine_train[2:14]))\nwine_test_scaled <- as.data.frame(scale(wine_test[2:14]))\n\n# do PCA on scaled data \nwine_train_PCA <- prcomp(wine_train_scaled)\nwine_test_PCA <- prcomp(wine_test_scaled)\n\n# the feature values after PCA run\nhead(wine_train_PCA$x)\n\n#standard deviations: gives more information, greatest variability is the first PC \nsapply(wine_train[2:14],sd) # for each attribute,before scaling  \nsapply(wine_train_scaled,sd)\nwine_train_PCA$sdev\n\n# Plot in order to decide how many Principal Components to retain\nscreeplot(wine_train_PCA, type=\"lines\")\n# The most obvious change in slope in the scree plot occurs at component 4, \n# which is the “elbow” of the scree plot. Therefore, \n# it cound be argued based on the basis of the scree plot that the \n# first three components should be retained.\n\n#prepare data for training and test\n# train just with the first 4 components cuz they have high standard deviations \n# you can perhaps play with the number of hidden nodes and/or do iterations to see computational time.\nwine_train_pca4 <- data.frame(V1 = wine_train[, \"V1\"], wine_train_PCA$x)\nwine_test_pca4 <- subset(wine_test_PCA$x,select = c(\"PC1\",\"PC2\",\"PC3\",\"PC4\"))\n# train model and record the time\nsystem.time(modelnn.pca <- neuralnet(V1 ~ PC1 + PC2 + PC3 + PC4 , \n                                     wine_train.pca, hidden = 10, \n                                     algorithm='rprop+',learningrate=0.01,rep=1))\n# higher computational time... why? Cuz PCA takes longer in general? \n#    answer: TA says neural net can take various time periods \n\nprop.table(table(wine_test$V1 == round((compute(modelnn.pca, wine_test.pca))$net.result)))\n# wow, true is 0.88% \n\n# ==================bonus from the TA (written by Jason), not copied correctly need to be fixed====\n# this part test how neural net generate different results each time \n\ncorrect  <- rep(0,20)\nnam  <- c()\nfor(i in 1:20){\n  set.seed(i)\n  wine <- wine[sample(nrow(wine),]\n  wine_train  <- wine[1:100,]\n  wine_test  <- wine[1:100,]\n  modelnn  <- neuralnet(V1 ~ V2 + V3 + V4 ) #fix this by including more variables \n  \n  temp_test  <- subset(wine_test, select = c('V2', \"V3\", \"V4\")) # same here \n  \n  a <- prop.table((compute(modelnn, temp_test)))\n  correct[i]  <- a[2] # get the true % \n #  nam  <- c(nam, names(a)[2]) # check R isn't flipping the value... not sure what this mean \n}\n\n# code not working, will fix later \n\n# if run 100 times neural net with PCA takes less time?  - said by Sarah ",
    "created" : 1425522328266.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2038934540",
    "id" : "FD5620E0",
    "lastKnownWriteTime" : 1418375071,
    "path" : "C:/Users/Santina Lin/SkyDrive/CPSC340/Tutorials/Tutorial5/Tutorial-5-scripts.R",
    "project_path" : "Tutorials/Tutorial5/Tutorial-5-scripts.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}