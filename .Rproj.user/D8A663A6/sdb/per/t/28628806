{
    "contents" : "library(e1071)\nlibrary(randomForest)\nlibrary(tree)\n\n# load data \ntraining<- read.table(\"LabNov10-train.csv\", sep = \",\", header = TRUE)\ntesting<- read.table(\"LabNov10-test.csv\", sep = \",\", header = TRUE)\n\n#extra code: \ntr <- tree(y~x1+x2+x3, data = training) # a single decision tree\nprediction.tr <- predict(tr, newdata = testing)\n\t# to take a look: \n\tplot(tr) \n\ttext(tr)\nerror.tr <- sqrt(sum((testing$y - prediction.tr)^2)/nrow(testing))\nerror.tr  # 153.916 Now we have a benchmark and now compare this to random forest \n\n\nrf_10 <- randomForest(y~x1+x2+x3,data=training,ntree=10)\npredictions.rf_10 <-predict(rf_10,newdata=testing)\nerror.rf_10 <-sqrt((sum((testing$y-predictions.rf_10)^2))/nrow(testing))\nerror.rf_10  #  146.7015\n\nrf_100 <- randomForest(y~x1+x2+x3,data=training,ntree=100)\npredictions.rf_100 <-predict(rf_100,newdata=testing)\nerror.rf_100<-sqrt((sum((testing$y-predictions.rf_100)^2))/nrow(testing))\nerror.rf_100  # 143.7546\n\n# now compare linear model and support vector machine \n\nrm <- glm(y ~ x1 + x2 + x3, data = training)\npredictions.rm<-predict(rm,newdata=testing)\nerror.rm<-sqrt((sum((testing$y-predictions.rm)^2))/nrow(testing))\nerror.rm #173.3578 \n\nsvm <- svm(y~x1+x2+x3,data=training)\npredictions.svm<-predict(svm,newdata=testing)\nerror.svm<-sqrt((sum((testing$y-predictions.svm)^2))/nrow(testing))\nerror.svm #143.7986\n\n# ensemble.  combine svm and linear regression together by averaging the predictions\npredictions.svm_rm<-(predictions.svm + predictions.rm)/2  #we're averaging the prediction\nerror.svm_rm<-sqrt((sum((testing$y-predictions.svm_rm)^2))/nrow(testing))\nerror.svm_rm  #148.1048  lower than the average of errors (143.7986+173.3578)/2 = 158.6\n\n# now we weight our prediction method, weight svm 0.9 and linear regression 0.1\npredictions.svm_rm<-(predictions.svm * 9 + predictions.rm)/10\nerror.svm_rm<-sqrt((sum((testing$y-predictions.svm_rm)^2))/nrow(testing))\nerror.svm_rm  # 142.7605 , a bit lower 50/50 weight \n\n# combine svm and random forest together \npredictions.svm_rf<-(predictions.svm + predictions.rf_10)/2\nerror.svm_rf<-sqrt((sum((testing$y-predictions.svm_rf)^2))/nrow(testing))\nerror.svm_rf  #  140.0745  \n\n#combine random forest and linear regression\n\npredictions.rf_glm<-(predictions.rf_10 + predictions.rm)/2\nerror.rf_glm<-sqrt((sum((testing$y-predictions.rf_glm)^2))/nrow(testing))\nerror.rf_glm  #  151.3052\n\n",
    "created" : 1425522303080.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2748126816",
    "id" : "28628806",
    "lastKnownWriteTime" : 1415666796,
    "path" : "C:/Users/Santina Lin/SkyDrive/CPSC340/Tutorials/Tutorial7/Tutorial-7-scripts.R",
    "project_path" : "Tutorials/Tutorial7/Tutorial-7-scripts.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}