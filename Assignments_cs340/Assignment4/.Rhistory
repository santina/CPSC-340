library(tm)         # for text mining
library(SnowballC)  # for using stemmming, finding common roots of words
library(plyr)       # for easy computation with data frames
library(dplyr)      # do this after loading plyr
source('./helperFunctions.R')
setwd("C:/Users/Santina Lin/SkyDrive/CPSC340/Assignments_cs340/Assignment4")
source('./helperFunctions.R')
list.files()
list.files("20news-bydate-test")
training_files <- list.files("20news-bydate-train", full.name = TRUE)
testing_files  <- list.files("20news-bydate-test", full.name = TRUE)
train_classes  <- getClasses(training_files)
test_classes  <- getClasses(testing_files)
test_classes
length(testing_files)
length(test_classes)
length(train_classes)
trainCorpusList <- alply(training_files, .margin = 1, function(f){
singleCorpus <- Corpus(DirSource(f,  encoding="UTF-8"))
})
testCorpusList <- alply(testing_files, .margin = 1, function(f){
singleCorpus <- Corpus(DirSource(f,  encoding="UTF-8"))
})
trainCorpusList <- processCorpusList(trainCorpusList)
testCorpusList <- processCorpusList(testCorpusList)
length(trainCorpusList)
length(testCorpusList)
togetherCorpus  <- c(trainCorpusList, testCorpusList)
allCorpus_train <- do.call(function(...) c(..., recursive = TRUE), togetherCorpus)
allCorpus_train
11314+7532
allCorpus_train <- do.call(function(...) c(..., recursive = TRUE), trainCorpusList)
allCorpus_train <- do.call(function(...) c(..., recursive = TRUE), trainCorpusList)
allCorpus_test <- do.call(function(...) c(..., recursive = TRUE), testCorpusList)
allCorpus  <- do.call(function(...) c(..., recursive = TRUE), togetherCorpus)
DTM_train <- DocumentTermMatrix(allCorpus_train,control=list(stemming = TRUE,weighting = weightTfIdf))
DTM_train
DTM_train <- removeSparseTerms(DTM_train, sparse=0.95)
DTM_train
DTM_train <- removeSparseTerms(DTM_train, sparse=0.99)
DTM_train
DTM_train <- removeSparseTerms(DTM_train, sparse=0.90)
DTM_train
DTM_train_dataframe <- as.data.frame(inspect(DTM_train))
DTM_train <- removeSparseTerms(DTM_train, sparse=0.85)
DTM_train
DTM_train_dataframe <- as.data.frame(inspect(DTM_train))
DTM_test <- DocumentTermMatrix(allCorpus_test,control=list(stemming = TRUE,weighting = weightTfIdf))
head(DTM_test)
nrow(DTM_test)
nrow(DTM_train)
DTM_all <- rbind(DTM_train, DTM_test)
ncol(DTM_test)
ncol(DTM_train)
DTM_train <- DocumentTermMatrix(allCorpus_train,control=list(stemming = TRUE,weighting = weightTfIdf))
DTM_all <- rbind(DTM_train, DTM_test)
ncol(DTM_train)
ncol(DTM_test)
nrow(DTM_test)
nrow(DTM_train)
DTM_all <- DocumentTermMatrix(allCorpus,control=list(stemming = TRUE,weighting = weightTfIdf))
nrow(DTM_all)
ncol(DTM_all)
DTM_all2 <- removeSparseTerms(DTM_all, sparse=0.85) # sparsity
ncol(DTM_all)
ncol(DTM_all2)
DTM_all
DTM_all2
nrow(DTM_train)
DTM_all2_train <- DTM_all2[1:11314]
DTM_train_dataframe <- as.data.frame(inspect(DTM_all2_train))
DTM_all2 <- as.data.frame(inspect(DTM_all2))
nrow(DTM_all2)
DTM_all2_train <- DTM_all2(1:11314)
DTM_all2_train <- DTM_all2[1:11314]
DTM_all2_train <- DTM_all2[1:11314, ]
SVM <- svm(DTM_all2_train,train_classes,kernel="linear")
library(tm)         # for text mining
library(SnowballC)  # for using stemmming, finding common roots of words
library(plyr)       # for easy computation with data frames
library(dplyr)      # do this after loading plyr
library(dplyr)      # do this after loading plyr
library(e1071)      # for SVM
SVM <- svm(DTM_all2_train,train_classes,kernel="linear")
nrow(DTM_all2_train)
ncol(DTM_all2_train)
DTM_all2_test  <- tail(DTM_all2, 7532)
PredictionSVM <- predict(SVM,DTM_all2_test)
table(PredictionSVM,test_classes)
predictionSVM
PredictionSVM
train_classes
table(PredictionSVM,test_classes)
prop.table(table(test_classes==PredictionSVM)) # 100% true
summary(SVM)
PredictionSVM
train_classes
train_classes <- as.factor(train_classes)
train_classes
SVM <- svm(DTM_all2_train,train_classes,kernel="linear")
PredictionSVM <- predict(SVM,DTM_all2_test)
test_classes
test_classes <- as.factor(test_classes)
test_classes
table(PredictionSVM,test_classes)
prop.table(table(test_classes==PredictionSVM)) # 100% true
summary(SVM)
DTM_all2
table(PredictionSVM,test_classes)
prop.table(table(test_classes==PredictionSVM))
classes_all <- c(train_classes, test_classes)
length(classes_all)
DTM_all2$class <- classes_all
a <- DTM_all2
a$test  <- rep(0, times = 11111)
DTM_all2_shuffled <- DTM_all2[sample(nrow(DTM_all2)), ]
nrow(DTM_all2_shuffled)/2
nrow(DTM_all2_shuffled)
18846/5
size  <- nrow(DTM_all2_shuffled)/5
size
18846 -  3769
18846-3770
15076/4
set1 <- head(DTM_all2_shuffled, 3770)
set2 <- DTM_all2_shuffled[3770:(3769*1), ]
round(nrow(DTM_all2_shuffled)/5 )
size <- round(nrow(DTM_all2_shuffled)/5)
set1 <- head(DTM_all2_shuffled, size)
set2 <- DTM_all2_shuffled[(size+1):(size*2), ]
set3 <- DTM_all2_shuffled[(size*2+1):(size*3), ]
set4 <- DTM_all2_shuffled[(size*3+1):(size*4), ]
set5 <- tail(DTM_all2_shuffled, 3770)
nrow(set2)
nrow(set3)
nrow(set4)
nrow(set5)
nrow(set1)
source('./helperFunctions.R')
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
source('./helperFunctions.R')
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
source('./helperFunctions.R')
source('./helperFunctions.R')
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
classes_all
classes_all <- factor(c(train_classes, test_classes))
classes_all
DTM_all2$class <- classes_all
DTM_all2_shuffled <- DTM_all2[sample(nrow(DTM_all2)), ]
size  <- nrow(DTM_all2_shuffled)/5
# 3769.2, doesn't divide evenly, make last set with 3770
size <- round(nrow(DTM_all2_shuffled)/5)
set1 <- head(DTM_all2_shuffled, size)
set2 <- DTM_all2_shuffled[(size+1):(size*2), ]
set3 <- DTM_all2_shuffled[(size*2+1):(size*3), ]
set4 <- DTM_all2_shuffled[(size*3+1):(size*4), ]
set5 <- tail(DTM_all2_shuffled, 3770)
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
classes_all <- factor(c(train_classes, test_classes))
classes_all <- as.factor(c(train_classes, test_classes))
classes_all
train_classes
c(train_classes, test_classes)
c(train_classes, test_classes) %>% as.factor()
a  <- (1,2,3)
a  <- {1,2,3}
a <- c(1,0,1)
b <- (1,0,1)
b <- c(1,0,1)
c(a,b)
class(a)
class(train_classes)
a <- as.factor(a)
b <- as.factor(b)
a
b
c(a,b)
a <- as.numeric
a
a <- c(1,0,1)
a
b <- as.numeric(b)
b
b <- c(1,0,1)
b
b <- as.factor(b)
b
b <- as.numeric(b)
b
nrow(DTM_all2)
DTM_all2[1:11314, ]$class <- train_classes
train_classes
DTM_all2[1:11314, ]$class <- train_classes
DTM_all2[11315:18846]$class <- test_classes
DTM_all2[11315:18846,]$class <- test_classes
DTM_all2[1,]$class
a
b
b <- c(1,0,1)
b
c(a,b)
d <- c(a,b)
d
d <- as.factor(b)
d <- as.factor(d)
d
d <- c(a,b)
d
d <- factor(d)
d
factor(c(a,b))
a <- as.factor(a)
b <- as.factor(b)
factor(c(a,b)
)
trainClass  <- getClasses(training_files) #11314 files in total
testClass  <- getClasses(testing_files)   #7532 files in total
trainClass
DTM_all2$class <- factor(c(trainClass, testClass))
DTM_all2_shuffled <- DTM_all2[sample(nrow(DTM_all2)), ]
size  <- nrow(DTM_all2_shuffled)/5
# 3769.2, doesn't divide evenly, make last set with 3770
size <- round(nrow(DTM_all2_shuffled)/5)
set1 <- head(DTM_all2_shuffled, size)
set2 <- DTM_all2_shuffled[(size+1):(size*2), ]
set3 <- DTM_all2_shuffled[(size*2+1):(size*3), ]
set4 <- DTM_all2_shuffled[(size*3+1):(size*4), ]
set5 <- tail(DTM_all2_shuffled, 3770)
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
DTM_all2$class
set1
head(set1)
source('./helperFunctions.R')
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
source('./helperFunctions.R')
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
source('./helperFunctions.R')
getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
table1 <- getConfusionMatrix_SVM(set1, set2, set3, set4, set5)
table2 <- getConfusionMatrix_SVM(set2, set1, set3, set4, set5)
table3 <- getConfusionMatrix_SVM(set3, set2, set1, set4, set5)
table4 <- getConfusionMatrix_SVM(set4, set2, set3, set1, set5)
table5 <- getConfusionMatrix_SVM(set5, set2, set3, set4, set1)
table 1
table1
t <- table1
t2 <- table2
t2
t[1]+t2[1]
t[1]
t
t2[1]
t2
t2[22]
t2[2]
summary <- data.frame()
summary[1,1] <- table1[1,1] + table2[1,1] + table3[1,1] + table4[1,1] + table5[1,1]
summary[1,2] <- table1[1,2] + table2[1,2] + table3[1,2] + table4[1,2] + table5[1,2]
summary[2,1] <- table1[2,1] + table2[2,1] + table3[2,1] + table4[2,1] + table5[2,1]
summary[2,2] <- table1[2,2] + table2[2,2] + table3[2,2] + table4[2,2] + table5[2,2]
summary
table1
table2
table3
table4
table5
2598 +2665+2647+2642+2630
summary
ncol(summary)
colnames(summary)
colnames(table1)
colnames(summary) <- c(0,1)
colnames
summary
rownames(summary) <- c(0,1)
summary
table1
summary[1,1]
summary
summary[1,2]
summary[2,2]
table1
table1[1,2]
TN <- summary[1,1]
FN <- summary[1,2]
FP <- summary[2,1]
TP <- summary[2,2]
specificity <- TN/(TN+FP)
sensitivity <- TP/(TP+FN)
specificity
sensitivity
predictionSummary <- table(PredictionSVM,test_classes)
specificity_all <- TN/(TN+FP)  #0.945
sensitivity_all <- TP/(TP+FN)  #0.346
specificity_all
TN <- predictionSummary[1,1]
FN <- predictionSummary[1,2]
FP <- predictionSummary[2,1]
TP <- predictionSummary[2,2]
specificity_all
sensitivity_all
predictionSummary <- table(PredictionSVM,test_classes)
TN <- predictionSummary[1,1]
FN <- predictionSummary[1,2]
FP <- predictionSummary[2,1]
TP <- predictionSummary[2,2]
specificity_all <- TN/(TN+FP)  #0.945
specificity_all
predictionSummary
summary
TN <- predictionSummary[1,1]
TN
5268/(5268+309)
13182/(13182+773)
TN_CV <- summary[1,1]
FN_CV <- summary[1,2]
FP_CV <- summary[2,1]
TP_CV <- summary[2,2]
#I'll treat 1 (comp) as positive
specificity <- TN_CV/(TN_CV+FP_CV)  #0.945
sensitivity <- TP_CV/(TP_CV+FN_CV)  #0.346
specificity_CV <- TN_CV/(TN_CV+FP_CV)  #0.945
sensitivity_CV <- TP_CV/(TP_CV+FN_CV)  #0.346
specificity_CV
sensitivity_CV
TN <- predictionSummary[1,1]
FN <- predictionSummary[1,2]
FP <- predictionSummary[2,1]
TP <- predictionSummary[2,2]
specificity <- TN/(TN+FP)  #0.9445939
sensitivity <- TP/(TP+FN)  #0.346
specificity
sensitivity
